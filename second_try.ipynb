{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9+utIKXY2i0mYOvL0wHjJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eiko58/Hippocampus_segmentation/blob/main/second_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Trd5XVYRSP3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader as DataLoader\n",
        "from torchvision import transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import glob\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import os.path\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import copy\n",
        "import torchvision.transforms.functional as TF\n",
        "import random\n",
        "import math\n",
        "import pandas as pd\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xtq_ovLeRiC1",
        "outputId": "cd8f6811-64cd-4520-8a94-ee2bccd8aa51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class img_dataset(Dataset):\n",
        "  def __init__(self, kind='train', transforms=False, center_crop=False):\n",
        "    self.center_crop = center_crop\n",
        "    self.transforms = transforms\n",
        "    self.kind = kind\n",
        "    super(Dataset,self).__init__()\n",
        "    path_kind = 'drive/MyDrive/hippocampus/' + kind\n",
        "    self.features = [cv2.cvtColor(cv2.imread(file),cv2.COLOR_BGR2GRAY) for file in glob.glob(path_kind+'/Total/*.jpg')] \n",
        "    self.targets = [cv2.cvtColor(cv2.imread(file),cv2.COLOR_BGR2GRAY) for file in glob.glob(path_kind+'/label/*.jpg')]\n",
        "    assert len(self.features) == len(self.targets), \"Something wrong with the dataset\"\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    feature, target = self.features[index], self.targets[index]\n",
        "    feature_tensor = torch.tensor(feature)\n",
        "    feature_tensor = torch.unsqueeze(feature_tensor/255, 0)\n",
        "    target_tensor = torch.tensor(target)/255\n",
        "    target_tensor = torch.round(target_tensor)\n",
        "    target_tensor = torch.unsqueeze(target_tensor, 0)\n",
        "    if self.center_crop:\n",
        "      feature_tensor = TF.center_crop(feature_tensor, 150)\n",
        "      target_tensor = TF.center_crop(target_tensor, 150)\n",
        "    if self.transforms:\n",
        "      if self.kind == 'train' or self.kind == 'balanced_train':\n",
        "        if random.uniform(0,1) > 0.8:\n",
        "                x_unif = random.uniform(0.5, 1.5)\n",
        "                feature_tensor = TF.adjust_gamma(feature_tensor, x_unif)\n",
        "        if random.uniform(0,1) > 0.8:\n",
        "                x1 = np.random.binomial(4, 0.5) - 2\n",
        "                y1 = np.random.binomial(4, 0.5) - 2\n",
        "                x2 = random.uniform(0.9, 1.1)\n",
        "                x3 = random.uniform(-5, 5)\n",
        "                feature_tensor = TF.affine(feature_tensor, angle=0, translate = [x1, y1], scale = x2, shear=x3)\n",
        "                target_tensor = TF.affine(target_tensor, angle=0, translate = [x1, y1], scale = x2, shear=x3) # think it's needed because of shear (?)\n",
        "        if random.uniform(0,1) > 0.8:\n",
        "                feature_tensor = TF.gaussian_blur(feature_tensor, 3)\n",
        "    return feature_tensor, target_tensor"
      ],
      "metadata": {
        "id": "wwPwLjtwT0CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, batchnorm=False):\n",
        "    super(DoubleConv, self).__init__()\n",
        "    self.batchnorm = batchnorm\n",
        "    if self.batchnorm:\n",
        "        self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=True),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "        )\n",
        "    else:\n",
        "        self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True), \n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=True),\n",
        "        nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "def init_xavier(model, retrain_seed):\n",
        "  torch.manual_seed(retrain_seed)\n",
        "  def init_weights(m):\n",
        "    if type(m) == nn.Linear and m.weight.requires_grad and m.bias.requires_grad:\n",
        "      g = nn.init.calculta_gain('tanh')\n",
        "      torch.nn.init.xavier_uniform_(m.weight, gain=g)\n",
        "      m.bias.data.fill_(0)\n",
        "  model.apply(init_weights)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "  def __init__(self, in_channels=1, out_channels=1, features=[64, 128, 256, 512], batchnorm=False, initialization=False):\n",
        "    super(UNet, self).__init__()\n",
        "    self.batchnorm = batchnorm\n",
        "    self.initialization = initialization\n",
        "    self.name = f'UNet_batchnorm_{self.batchnorm}_initialization_{self.initialization}'\n",
        "    self.downs = nn.ModuleList()\n",
        "    self.ups = nn.ModuleList()\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    # Down part of UNet\n",
        "    for feature in features:\n",
        "      self.downs.append(DoubleConv(in_channels, feature, batchnorm=self.batchnorm))\n",
        "      in_channels = feature\n",
        "\n",
        "    # Up part of UNet\n",
        "    for feature in reversed(features):\n",
        "      self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2)) #feature*2 because of concatination\n",
        "      self.ups.append(DoubleConv(feature*2, feature, batchnorm=self.batchnorm))\n",
        "    \n",
        "    # Bottleneck\n",
        "    self.bottleneck = DoubleConv(features[-1], features[-1]*2, batchnorm=self.batchnorm)\n",
        "\n",
        "    # Final Conv\n",
        "    self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    skip_connections = []\n",
        "\n",
        "    for down in self.downs:\n",
        "      x = down(x)\n",
        "      skip_connections.append(x) # first has highest resolution\n",
        "      x = self.pool(x)\n",
        "    \n",
        "    x = self.bottleneck(x)\n",
        "    skip_connections = skip_connections[::-1]\n",
        "\n",
        "    for i in range(0, len(self.ups), 2):\n",
        "      x = self.ups[i](x) #ConvTranspose\n",
        "      skip_connection = skip_connections[i//2]\n",
        "      if x.shape != skip_connection.shape:\n",
        "        x = transforms.functional.resize(x, skip_connection.shape[2:]) #ignoring batch size and channel size\n",
        "      concat_skip = torch.concat((skip_connection, x), dim=1) #dim=1 is channel dimension\n",
        "      x = self.ups[i+1](concat_skip) # DoubleConv\n",
        "    \n",
        "    return self.final_conv(x)"
      ],
      "metadata": {
        "id": "F32R6RtqWLFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class diceloss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(diceloss, self).__init__()\n",
        "  def forward(self, outcome, label):\n",
        "    return 1-(2*(outcome*label).sum()+ 1e-5) / ((outcome+label).sum()+ 1e-8) "
      ],
      "metadata": {
        "id": "wA9ZgNq4oLZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_loss(outputs, labels, batch_size, criterion): #gives empty_loss and nempty_loss for batch\n",
        "  loss_empty_labels = []\n",
        "  loss_not_empty_labels = []\n",
        "  for i in range(batch_size):\n",
        "    if torch.sum(labels[i]) == 0:\n",
        "      loss_empty_labels.append(criterion(outputs[i].detach(), labels[i]).item())\n",
        "    else:\n",
        "      loss_not_empty_labels.append(criterion(outputs[i].detach(), labels[i]).item())\n",
        "  return loss_empty_labels, loss_not_empty_labels"
      ],
      "metadata": {
        "id": "OkddX5jad2xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(p_trdata, transforms, model, criterion, epochs, crop=False, balanced=False, seed): #epochs = tuple\n",
        "  # make dataloaders\n",
        "  print('train')\n",
        "  if not balanced:\n",
        "    tr_dataset = img_dataset(kind='train', transforms=transforms, crop=crop)\n",
        "  else:\n",
        "    tr_dataset = img_dataset(kind='balanced_train', transforms=transforms, crop=crop)\n",
        "  if p_trdata != 1:\n",
        "      keep = math.floor(len(tr_dataset)*p_trdata)\n",
        "      tr_dataset, _ = random_split(tr_dataset, [keep, len(tr_dataset)-keep], generator=torch.Generator().manual_seed(seed))\n",
        "  tr_dataloader = DataLoader(tr_dataset, batch_size=8, shuffle=True)\n",
        "  print('val')\n",
        "  val_dataloader = DataLoader(img_dataset(kind='validation'), batch_size=8, shuffle=False)\n",
        "\n",
        "  print('initialization')\n",
        "  if model.initialization == True:\n",
        "    init_xavier(model, seed)\n",
        "  s = nn.Sigmoid() # for image saving\n",
        "\n",
        "  # make folder\n",
        "  print('make folders')\n",
        "  full_model_name = f'{model.name}_transforms_{transforms}_criterion_{criterion}_ptrdata_{p_trdata}_nepochs_{nepochs}_seed_{seed}'\n",
        "  path = 'drive/MyDrive/models/'+full_model_name\n",
        "  if not os.path.isdir(path):\n",
        "    os.mkdir(path)\n",
        "\n",
        "  # train\n",
        "  epochs_tr_empty_loss = []\n",
        "  epochs_tr_nempty_loss = []\n",
        "  epochs_tr_total_loss = []\n",
        "  epochs_val_empty_loss = []\n",
        "  epochs_val_nempty_loss = []\n",
        "  epochs_val_total_loss = []\n",
        "  min_val_loss = float(\"inf\")\n",
        "  start_epoch, end_epoch = epochs\n",
        "  for epoch in range(start_epoch, end_epoch): \n",
        "    print(epoch)\n",
        "    empty_loss = []\n",
        "    nempty_loss = []\n",
        "    total_loss = []\n",
        "    model.train()\n",
        "    for i, data in enumerate(tr_dataloader):  \n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)         \n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        el, nel = batch_loss(outputs, labels, outputs.shape[0], criterion)\n",
        "        empty_loss.extend(el)\n",
        "        nempty_loss.extend(nel)\n",
        "        total_loss.append(loss.item())\n",
        "\n",
        "        loss.backward()                    \n",
        "        optimizer.step()                   \n",
        "    \n",
        "    # track training error once per epoch\n",
        "    epochs_tr_empty_loss.append(np.mean(np.array(empty_loss)))\n",
        "    epochs_tr_nempty_loss.append(np.mean(np.array(nempty_loss)))\n",
        "    epochs_tr_total_loss.append(np.mean(np.array(total_loss)))\n",
        "\n",
        "    # track validation error once per epoch\n",
        "    model.eval()\n",
        "    val_empty_loss = []\n",
        "    val_nempty_loss = []\n",
        "    val_total_loss = []\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_dataloader):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            vel, vnel = batch_loss(outputs, labels, outputs.shape[0], criterion)\n",
        "            vloss = criterion(outputs, labels).item()\n",
        "            val_empty_loss.extend(vel)\n",
        "            val_nempty_loss.extend(vnel)\n",
        "            val_total_loss.append(vloss)\n",
        "    epochs_val_empty_loss.append(np.mean(np.array(val_empty_loss)))\n",
        "    epochs_val_nempty_loss.append(np.mean(np.array(val_nempty_loss)))\n",
        "    epochs_val_total_loss.append(np.mean(np.array(val_total_loss)))\n",
        "\n",
        "    # save model state if its better than the others\n",
        "    if np.mean(np.array(val_total_loss)) < min_val_loss:\n",
        "      torch.save(model.state_dict(), path+'/model.pth')\n",
        "\n",
        "    # save a predicted image once per epoch\n",
        "    if epoch == 0:\n",
        "      u = 0\n",
        "      for validation_features, validation_targets in val_dataloader:\n",
        "          u+=1\n",
        "          if u==14:\n",
        "                break\n",
        "      validation_features = validation_features.to(device)\n",
        "      save_image(validation_targets[4], path+'/validation_target.png')\n",
        "      del validation_targets\n",
        "    image_name_nempty = f'/validation_notempty_prediction_{epoch}.png'\n",
        "    image_name_empty = f'/validation_empty_prediction_{epoch}.png'\n",
        "    predictions = s(model(validation_features))\n",
        "    save_image(predictions[4], path+image_name_nempty)\n",
        "    save_image(predictions[0], path+image_name_nempty)\n",
        "    \n",
        "\n",
        "  # save training and validation errors as csv\n",
        "  d = {}\n",
        "  d['tr_empty'] = epochs_tr_empty_loss\n",
        "  d['tr_not_empty'] = epochs_tr_nempty_loss\n",
        "  d['tr_total'] = epochs_tr_total_loss\n",
        "  d['val_empty'] = epochs_val_empty_loss\n",
        "  d['val_not_empty'] = epochs_val_nempty_loss\n",
        "  d['val_total'] = epochs_val_total_loss\n",
        "  df = pd.DataFrame(d)\n",
        "  df.to_csv(path+'/losses.txt')"
      ],
      "metadata": {
        "id": "F2UypqOJWMDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b425q7S-wMiU",
        "outputId": "cee164ce-82c7-4ef3-b03d-05f092762596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criterion, optimizer, model => call train function\n",
        "dice = diceloss()\n",
        "#bce = nn.BCEWithLogitsLoss()\n",
        "model = UNet(batchnorm = True, initialization = True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "model.to(device)\n",
        "train(p_trdata = 0.2, transforms = True, model = model, criterion = dice, epochs = (0,10), seed = 1234)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyKKCYUBqCNS",
        "outputId": "9cfa3159-d0b2-4c65-ac0e-0fd9f4d0000f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "val\n",
            "initialization\n",
            "make folders\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ]
    }
  ]
}
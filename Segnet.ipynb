{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eiko58/Hippocampus_segmentation/blob/main/Segnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_Trd5XVYRSP3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader as DataLoader\n",
        "from torchvision import transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import glob\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import os.path\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import copy\n",
        "import torchvision.transforms.functional as TF\n",
        "import random\n",
        "import math\n",
        "import pandas as pd\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xtq_ovLeRiC1",
        "outputId": "3b274d08-4653-4694-d704-424bfef3b678"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class img_dataset(Dataset):\n",
        "  def __init__(self, kind='train', transforms=False, center_crop=False):\n",
        "    self.center_crop = center_crop\n",
        "    self.transforms = transforms\n",
        "    self.kind = kind\n",
        "    super(Dataset,self).__init__()\n",
        "    path_kind = 'drive/MyDrive/hippocampus/' + kind\n",
        "    self.features = [cv2.cvtColor(cv2.imread(file),cv2.COLOR_BGR2GRAY) for file in glob.glob(path_kind+'/Total/*.jpg')] \n",
        "    self.targets = [cv2.cvtColor(cv2.imread(file),cv2.COLOR_BGR2GRAY) for file in glob.glob(path_kind+'/label/*.jpg')]\n",
        "    assert len(self.features) == len(self.targets), \"Something wrong with the dataset\"\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    feature, target = self.features[index], self.targets[index]\n",
        "    feature_tensor = torch.tensor(feature)\n",
        "    feature_tensor = torch.unsqueeze(feature_tensor/255, 0)\n",
        "    target_tensor = torch.tensor(target)/255\n",
        "    target_tensor = torch.round(target_tensor)\n",
        "    target_tensor = torch.unsqueeze(target_tensor, 0)\n",
        "    if self.center_crop:\n",
        "      feature_tensor = TF.center_crop(feature_tensor, 150)\n",
        "      target_tensor = TF.center_crop(target_tensor, 150)\n",
        "    if self.transforms:\n",
        "      if self.kind == 'train' or self.kind == 'balanced_train':\n",
        "        if random.uniform(0,1) > 0.8:\n",
        "                x_unif = random.uniform(0.5, 1.5)\n",
        "                feature_tensor = TF.adjust_gamma(feature_tensor, x_unif)\n",
        "        if random.uniform(0,1) > 0.8:\n",
        "                x1 = np.random.binomial(4, 0.5) - 2\n",
        "                y1 = np.random.binomial(4, 0.5) - 2\n",
        "                x2 = random.uniform(0.9, 1.1)\n",
        "                x3 = random.uniform(-5, 5)\n",
        "                feature_tensor = TF.affine(feature_tensor, angle=0, translate = [x1, y1], scale = x2, shear=x3)\n",
        "                target_tensor = TF.affine(target_tensor, angle=0, translate = [x1, y1], scale = x2, shear=x3) # think it's needed because of shear (?)\n",
        "        if random.uniform(0,1) > 0.8:\n",
        "                feature_tensor = TF.gaussian_blur(feature_tensor, 3)\n",
        "    return feature_tensor, target_tensor"
      ],
      "metadata": {
        "id": "wwPwLjtwT0CX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, batchnorm=False):\n",
        "    super(DoubleConv, self).__init__()\n",
        "    self.batchnorm = batchnorm\n",
        "    if self.batchnorm:\n",
        "        self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=True),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "        )\n",
        "    else:\n",
        "        self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True), \n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=True),\n",
        "        nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "def init_xavier(model, retrain_seed):\n",
        "  torch.manual_seed(retrain_seed)\n",
        "  def init_weights(m):\n",
        "    if type(m) == nn.Linear and m.weight.requires_grad and m.bias.requires_grad:\n",
        "      g = nn.init.calculta_gain('ReLU')\n",
        "      torch.nn.init.xavier_uniform_(m.weight, gain=g)\n",
        "      m.bias.data.fill_(0)\n",
        "  model.apply(init_weights)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "  def __init__(self, in_channels=1, out_channels=1, features=[64, 128, 256, 512], batchnorm=False, initialization=False):\n",
        "    super(UNet, self).__init__()\n",
        "    self.batchnorm = batchnorm\n",
        "    self.initialization = initialization\n",
        "    self.name = f'UNet_batchnorm_{self.batchnorm}_initialization_{self.initialization}'\n",
        "    self.downs = nn.ModuleList()\n",
        "    self.ups = nn.ModuleList()\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    # Down part of UNet\n",
        "    for feature in features:\n",
        "      self.downs.append(DoubleConv(in_channels, feature, batchnorm=self.batchnorm))\n",
        "      in_channels = feature\n",
        "\n",
        "    # Up part of UNet\n",
        "    for feature in reversed(features):\n",
        "      self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2)) #feature*2 because of concatination\n",
        "      self.ups.append(DoubleConv(feature*2, feature, batchnorm=self.batchnorm))\n",
        "    \n",
        "    # Bottleneck\n",
        "    self.bottleneck = DoubleConv(features[-1], features[-1]*2, batchnorm=self.batchnorm)\n",
        "\n",
        "    # Final Conv\n",
        "    self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    skip_connections = []\n",
        "\n",
        "    for down in self.downs:\n",
        "      x = down(x)\n",
        "      skip_connections.append(x) # first has highest resolution\n",
        "      x = self.pool(x)\n",
        "    \n",
        "    x = self.bottleneck(x)\n",
        "    skip_connections = skip_connections[::-1]\n",
        "\n",
        "    for i in range(0, len(self.ups), 2):\n",
        "      x = self.ups[i](x) #ConvTranspose\n",
        "      skip_connection = skip_connections[i//2]\n",
        "      if x.shape != skip_connection.shape:\n",
        "        x = transforms.functional.resize(x, skip_connection.shape[2:]) #ignoring batch size and channel size\n",
        "      concat_skip = torch.concat((skip_connection, x), dim=1) #dim=1 is channel dimension\n",
        "      x = self.ups[i+1](concat_skip) # DoubleConv\n",
        "    \n",
        "    return self.final_conv(x)"
      ],
      "metadata": {
        "id": "F32R6RtqWLFu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = nn.Sigmoid()\n",
        "class diceloss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(diceloss, self).__init__()\n",
        "  def forward(self, outcome, label):\n",
        "    return 1-(2*(s(outcome)*label).sum()+ 1e-5) / ((s(outcome)+label).sum()+ 1e-8) "
      ],
      "metadata": {
        "id": "wA9ZgNq4oLZE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_loss(outputs, labels, batch_size, criterion): #gives empty_loss and nempty_loss for batch\n",
        "  loss_empty_labels = []\n",
        "  loss_not_empty_labels = []\n",
        "  for i in range(batch_size):\n",
        "    if torch.sum(labels[i]) == 0:\n",
        "      loss_empty_labels.append(criterion(outputs[i].detach(), labels[i]).item())\n",
        "    else:\n",
        "      loss_not_empty_labels.append(criterion(outputs[i].detach(), labels[i]).item())\n",
        "  return loss_empty_labels, loss_not_empty_labels"
      ],
      "metadata": {
        "id": "OkddX5jad2xv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(p_trdata, transforms, model, criterion, epochs, seed, crop=False, balanced=False): #epochs = tuple\n",
        "  # make dataloaders\n",
        "  print('train')\n",
        "  if not balanced:\n",
        "    tr_dataset = img_dataset(kind='train', transforms=transforms, center_crop=crop)\n",
        "  else:\n",
        "    tr_dataset = img_dataset(kind='balanced_train', transforms=transforms, center_crop=crop)\n",
        "  if p_trdata != 1:\n",
        "      keep = math.floor(len(tr_dataset)*p_trdata)\n",
        "      tr_dataset, _ = random_split(tr_dataset, [keep, len(tr_dataset)-keep], generator=torch.Generator().manual_seed(seed))\n",
        "  tr_dataloader = DataLoader(tr_dataset, batch_size=8, shuffle=True)\n",
        "  print('val')\n",
        "  val_dataset = img_dataset(kind='validation', transforms=False, center_crop=crop)\n",
        "  val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "  print('initialization')\n",
        "  if model.initialization == True:\n",
        "    init_xavier(model, seed)\n",
        "  s = nn.Sigmoid() # for image saving\n",
        "\n",
        "  # make folder\n",
        "  print('make folders')\n",
        "  full_model_name = f'{model.name}_transforms_{transforms}_criterion_{criterion}_ptrdata_{p_trdata}_seed_{seed}_crop_{crop}_balanced_{balanced}'\n",
        "  path = 'drive/MyDrive/models/'+full_model_name\n",
        "  if not os.path.isdir(path):\n",
        "    os.mkdir(path)\n",
        "\n",
        "  # train\n",
        "  epochs_tr_empty_loss = []\n",
        "  epochs_tr_nempty_loss = []\n",
        "  epochs_tr_total_loss = []\n",
        "  epochs_val_empty_loss = []\n",
        "  epochs_val_nempty_loss = []\n",
        "  epochs_val_total_loss = []\n",
        "  min_val_loss = float(\"inf\")\n",
        "  start_epoch, end_epoch = epochs\n",
        "  for epoch in range(start_epoch, end_epoch): \n",
        "    print(epoch)\n",
        "    empty_loss = []\n",
        "    nempty_loss = []\n",
        "    total_loss = []\n",
        "    model.train()\n",
        "    for i, data in enumerate(tr_dataloader):  \n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)         \n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        el, nel = batch_loss(outputs, labels, outputs.shape[0], criterion)\n",
        "        empty_loss.extend(el)\n",
        "        nempty_loss.extend(nel)\n",
        "        total_loss.append(loss.item())\n",
        "\n",
        "        loss.backward()                    \n",
        "        optimizer.step()                   \n",
        "    \n",
        "    # track training error once per epoch\n",
        "    epochs_tr_empty_loss.append(np.mean(np.array(empty_loss)))\n",
        "    epochs_tr_nempty_loss.append(np.mean(np.array(nempty_loss)))\n",
        "    epochs_tr_total_loss.append(np.mean(np.array(total_loss)))\n",
        "\n",
        "    # track validation error once per epoch\n",
        "    model.eval()\n",
        "    val_empty_loss = []\n",
        "    val_nempty_loss = []\n",
        "    val_total_loss = []\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_dataloader):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            vel, vnel = batch_loss(outputs, labels, outputs.shape[0], criterion)\n",
        "            vloss = criterion(outputs, labels).item()\n",
        "            val_empty_loss.extend(vel)\n",
        "            val_nempty_loss.extend(vnel)\n",
        "            val_total_loss.append(vloss)\n",
        "    epochs_val_empty_loss.append(round(np.mean(np.array(val_empty_loss)), 5))\n",
        "    epochs_val_nempty_loss.append(round(np.mean(np.array(val_nempty_loss)), 5))\n",
        "    epochs_val_total_loss.append(round(np.mean(np.array(val_total_loss)), 5))\n",
        "\n",
        "    # save model state if its better than the others\n",
        "    if np.mean(np.array(val_total_loss)) < min_val_loss:\n",
        "      torch.save(model.state_dict(), path+'/model.pth')\n",
        "      min_val_loss = np.mean(np.array(val_total_loss))\n",
        "\n",
        "    # save a predicted image once per epoch\n",
        "    if epoch == start_epoch:\n",
        "      u = 0\n",
        "      for validation_features, validation_targets in val_dataloader:\n",
        "          u+=1\n",
        "          if u==14:\n",
        "                break\n",
        "      validation_features = validation_features.to(device)\n",
        "      save_image(validation_targets[4], path+'/validation_target_nonempty.png')\n",
        "      save_image(validation_features[4], path+'/validation_feature_nonempty.png')\n",
        "      save_image(validation_targets[0], path+'/validation_target_empty.png')\n",
        "      save_image(validation_features[0], path+'/validation_feature_empty.png')\n",
        "      del validation_targets\n",
        "    image_name_nempty = f'/validation_notempty_prediction_{epoch}.png'\n",
        "    image_name_empty = f'/validation_empty_prediction_{epoch}.png'\n",
        "    predictions = s(model(validation_features))\n",
        "    save_image(predictions[4], path+image_name_nempty)\n",
        "    save_image(predictions[0], path+image_name_empty)\n",
        "    \n",
        "\n",
        "  # save training and validation errors as csv\n",
        "  d = {}\n",
        "  d['tr_empty'] = epochs_tr_empty_loss\n",
        "  d['tr_not_empty'] = epochs_tr_nempty_loss\n",
        "  d['tr_total'] = epochs_tr_total_loss\n",
        "  d['val_empty'] = epochs_val_empty_loss\n",
        "  d['val_not_empty'] = epochs_val_nempty_loss\n",
        "  d['val_total'] = epochs_val_total_loss\n",
        "  df = pd.DataFrame(d)\n",
        "  df.to_csv(path+'/losses.txt')"
      ],
      "metadata": {
        "id": "F2UypqOJWMDt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b425q7S-wMiU",
        "outputId": "fcdc2d85-fef3-419a-9289-03f590f6e146"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criterion, optimizer, model => call train function\n",
        "dice = diceloss()\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "model = UNet(batchnorm = True, initialization = True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "model.to(device)\n",
        "train(p_trdata = 1.0, transforms = True, model = model, criterion = bce, epochs = (0,20), crop=False, balanced=True, seed = 1234)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyKKCYUBqCNS",
        "outputId": "b355c108-d635-490f-81d0-5f18a31a5819"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "val\n",
            "initialization\n",
            "make folders\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, batchnorm=False, initialization=False):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.batchnorm = batchnorm\n",
        "    self.initialization = initialization\n",
        "    self.name = f'Autoencoder_batchnorm_{self.batchnorm}_initialization_{self.initialization}'\n",
        "    self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.down_conv1 = nn.Conv2d(1,64,kernel_size=3)\n",
        "    self.norm_1 = nn.BatchNorm2d(64)\n",
        "    self.down_conv2 = nn.Conv2d(64,128,kernel_size=3)\n",
        "    self.norm_2 = nn.BatchNorm2d(128)\n",
        "    self.down_conv3 = nn.Conv2d(128,256,kernel_size=3)\n",
        "    self.norm_3 = nn.BatchNorm2d(256)\n",
        "    self.up_conv1 = nn.ConvTranspose2d(256,128,kernel_size=3)\n",
        "    self.up_conv2 = nn.ConvTranspose2d(128,64,kernel_size=3)\n",
        "    self.up_conv3 = nn.ConvTranspose2d(64,1,kernel_size=3)\n",
        "    self.out = nn.Sigmoid()\n",
        "    self.upsample = nn.UpsamplingBilinear2d(scale_factor=2)\n",
        "    self.conv = nn.Conv2d(256,256,kernel_size=3)\n",
        "\n",
        "\n",
        "  def forward(self,image):\n",
        "    if self.batchnorm:\n",
        "      #encoder\n",
        "      x = self.down_conv1(image)\n",
        "      x = F.relu(x)\n",
        "      x = self.norm_1(x)\n",
        "      x = self.max_pool(x)\n",
        "      #print(x1.size())\n",
        "      #print(x2.size())\n",
        "      x = self.down_conv2(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.norm_2(x)\n",
        "      x = self.max_pool(x)\n",
        "      #print(x3.size())\n",
        "      #print(x4.size())\n",
        "      x = self.down_conv3(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.norm_3(x)\n",
        "      x = self.max_pool(x)\n",
        "\n",
        "      #decoder\n",
        "      x = self.up_conv1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.norm_2(x)\n",
        "      x = self.up_conv2(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.norm_1(x) \n",
        "      x = self.up_conv3(x)\n",
        "      print(x.size())\n",
        "      \n",
        "      x = self.out(x)\n",
        "      return x\n",
        "\n",
        "    else:\n",
        "       #encoder\n",
        "      x = self.down_conv1(image)\n",
        "      x = F.relu(x)\n",
        "      x = self.max_pool(x)\n",
        "      print(x.size())\n",
        "      #print(x2.size())\n",
        "      x = self.down_conv2(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.max_pool(x)\n",
        "      print(x.size())\n",
        "      #print(x4.size())\n",
        "      x = self.down_conv3(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.max_pool(x)\n",
        "      print(x.size())\n",
        "\n",
        "      x = self.conv(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.upsample(x)\n",
        "      #decoder\n",
        "      x = self.up_conv1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.upsample(x)\n",
        "  \n",
        "      print(x.size())\n",
        "      x = self.up_conv2(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.upsample(x)\n",
        "  \n",
        "      print(x.size()) \n",
        "      x = self.up_conv3(x)\n",
        "      print(x.size())\n",
        "      x = self.out(x)\n",
        "\n",
        "      return x\n"
      ],
      "metadata": {
        "id": "aFQsargmz6G2"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import padding\n",
        "class SegNet(nn.Module):\n",
        "  def __init__(self, batchnorm = False, initialization = False):\n",
        "    super(SegNet, self).__init__()\n",
        "    self.batchnorm = batchnorm\n",
        "    self.initialization = initialization\n",
        "    self.name = f'SegNet_batchnorm_{self.batchnorm}_initialization_{self.initialization}'\n",
        "    self.MaxEn = nn.MaxPool2d(2,2,return_indices=True)\n",
        "    self.ConvEn11 = nn.Conv2d(1,64,kernel_size=3,padding=1)\n",
        "    self.BNEn11 = nn.BatchNorm2d(64,momentum=0.5)\n",
        "    self.ConvEn12 = nn.Conv2d(64,64,kernel_size=3, padding=1)\n",
        "    self.BNEn12 = nn.BatchNorm2d(64,momentum=0.5)\n",
        "\n",
        "    self.ConvEn21 = nn.Conv2d(64,128,kernel_size=3,padding=1)\n",
        "    self.BNEn21 = nn.BatchNorm2d(128,momentum=0.5)\n",
        "    self.ConvEn22 = nn.Conv2d(128,128,kernel_size=3, padding=1)\n",
        "    self.BNEn22 = nn.BatchNorm2d(128,momentum=0.5)\n",
        "\n",
        "    self.ConvEn31 = nn.Conv2d(128,256,kernel_size=3,padding=1)\n",
        "    self.BNEn31 = nn.BatchNorm2d(256,momentum=0.5)\n",
        "    self.ConvEn32 = nn.Conv2d(256,256,kernel_size=3, padding=1)\n",
        "    self.BNEn32 = nn.BatchNorm2d(256,momentum=0.5)\n",
        "    self.ConvEn33 = nn.Conv2d(256,256,kernel_size=3,padding=1)\n",
        "    self.BNEn33 = nn.BatchNorm2d(256,momentum=0.5)\n",
        "\n",
        "    self.ConvEn41 = nn.Conv2d(256,512,kernel_size=3,padding=1)\n",
        "    self.BNEn41 = nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.ConvEn42 = nn.Conv2d(512,512,kernel_size=3, padding=1)\n",
        "    self.BNEn42 = nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.ConvEn43 = nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
        "    self.BNEn43 = nn.BatchNorm2d(512,momentum=0.5)\n",
        "\n",
        "    self.ConvEn51 = nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
        "    self.BNEn51 = nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.ConvEn52 = nn.Conv2d(512,512,kernel_size=3, padding=1)\n",
        "    self.BNEn52 = nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.ConvEn53 = nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
        "    self.BNEn53 = nn.BatchNorm2d(512,momentum=0.5)\n",
        "\n",
        "    #Decoding\n",
        "    self.MaxDe = nn.MaxUnpool2d(2,2)\n",
        "    \n",
        "    self.ConvDe53 = nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
        "    self.BNDe53 = nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.ConvDe52 = nn.Conv2d(512,512,kernel_size=3, padding=1)\n",
        "    self.BNDe52 = nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.ConvDe51 = nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
        "    self.BNDe51 = nn.BatchNorm2d(512,momentum=0.5)\n",
        "\n",
        "    self.ConvDe43 = nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
        "    self.BNDe43 = nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.ConvDe42 = nn.Conv2d(512,512,kernel_size=3, padding=1)\n",
        "    self.BNDe42 = nn.BatchNorm2d(512,momentum=0.5)\n",
        "    self.ConvDe41 = nn.Conv2d(512,256,kernel_size=3,padding=1)\n",
        "    self.BNDe41 = nn.BatchNorm2d(256,momentum=0.5)\n",
        "\n",
        "    self.ConvDe33 = nn.Conv2d(256,256,kernel_size=3,padding=1)\n",
        "    self.BNDe33 = nn.BatchNorm2d(256,momentum=0.5)\n",
        "    self.ConvDe32 = nn.Conv2d(256,256,kernel_size=3, padding=1)\n",
        "    self.BNDe32 = nn.BatchNorm2d(256,momentum=0.5)\n",
        "    self.ConvDe31 = nn.Conv2d(256,128,kernel_size=3,padding=1)\n",
        "    self.BNDe31 = nn.BatchNorm2d(128,momentum=0.5)\n",
        "\n",
        "    self.ConvDe22 = nn.Conv2d(128,128,kernel_size=3, padding=1)\n",
        "    self.BNDe22 = nn.BatchNorm2d(128,momentum=0.5)\n",
        "    self.ConvDe21 = nn.Conv2d(128,64,kernel_size=3,padding=1)\n",
        "    self.BNDe21 = nn.BatchNorm2d(64,momentum=0.5)\n",
        "\n",
        "    self.ConvDe12 = nn.Conv2d(64,64,kernel_size=3, padding=1)\n",
        "    self.BNDe12 = nn.BatchNorm2d(64,momentum=0.5)\n",
        "    self.ConvDe11 = nn.Conv2d(64,1,kernel_size=3,padding=1)\n",
        "    self.BNDe11 = nn.BatchNorm2d(1,momentum=0.5)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    if self.batchnorm:\n",
        "      x = F.relu(self.BNEn11(self.ConvEn11(x)))\n",
        "      x = F.relu(self.BNEn12(self.ConvEn12(x)))\n",
        "      x, ind1 = self.MaxEn(x)\n",
        "      size1 = x.size()\n",
        "\n",
        "      x = F.relu(self.BNEn21(self.ConvEn21(x)))\n",
        "      x = F.relu(self.BNEn22(self.ConvEn22(x)))\n",
        "      x, ind2 = self.MaxEn(x)\n",
        "      size2 = x.size()\n",
        "\n",
        "      x = F.relu(self.BNEn31(self.ConvEn31(x)))\n",
        "      x = F.relu(self.BNEn32(self.ConvEn32(x)))\n",
        "      x = F.relu(self.BNEn33(self.ConvEn33(x)))\n",
        "      x, ind3 = self.MaxEn(x)\n",
        "      size3 = x.size()\n",
        "\n",
        "      x = F.relu(self.BNEn41(self.ConvEn41(x)))\n",
        "      x = F.relu(self.BNEn42(self.ConvEn42(x)))\n",
        "      x = F.relu(self.BNEn43(self.ConvEn43(x)))\n",
        "      x, ind4 = self.MaxEn(x)\n",
        "      size4 = x.size()\n",
        "\n",
        "      x = F.relu(self.BNEn51(self.ConvEn51(x)))\n",
        "      x = F.relu(self.BNEn52(self.ConvEn52(x)))\n",
        "      x = F.relu(self.BNEn53(self.ConvEn53(x)))\n",
        "      x, ind5 = self.MaxEn(x)\n",
        "      size5 = x.size()\n",
        "\n",
        "      #Decoder\n",
        "      x = self.MaxDe(x, ind5, output_size=size4)\n",
        "      x = F.relu(self.BNDe53(self.ConvDe53(x)))\n",
        "      x = F.relu(self.BNDe52(self.ConvDe52(x)))\n",
        "      x = F.relu(self.BNDe51(self.ConvDe51(x)))\n",
        "\n",
        "      x = self.MaxDe(x, ind4, output_size=size3)\n",
        "      x = F.relu(self.BNDe43(self.ConvDe43(x)))\n",
        "      x = F.relu(self.BNDe42(self.ConvDe42(x)))\n",
        "      x = F.relu(self.BNDe41(self.ConvDe41(x)))\n",
        "\n",
        "      x = self.MaxDe(x, ind3, output_size=size2)\n",
        "      x = F.relu(self.BNDe33(self.ConvDe33(x)))\n",
        "      x = F.relu(self.BNDe32(self.ConvDe32(x)))\n",
        "      x = F.relu(self.BNDe31(self.ConvDe31(x)))\n",
        "\n",
        "      x = self.MaxDe(x, ind2, output_size=size1)\n",
        "      x = F.relu(self.BNDe22(self.ConvDe22(x)))\n",
        "      x = F.relu(self.BNDe21(self.ConvDe21(x)))\n",
        "\n",
        "      x = self.MaxDe(x, ind1)\n",
        "      x = F.relu(self.BNDe12(self.ConvDe12(x)))\n",
        "      x = self.ConvDe11(x)\n",
        "      return x\n",
        "    \n",
        "    else:\n",
        "      x = F.relu(self.ConvEn11(x))\n",
        "      x = F.relu(self.ConvEn12(x))\n",
        "      x, ind1 = self.MaxEn(x)\n",
        "      size1 = x.size()\n",
        "\n",
        "      x = F.relu(self.ConvEn21(x))\n",
        "      x = F.relu(self.ConvEn22(x))\n",
        "      x, ind2 = self.MaxEn(x)\n",
        "      size2 = x.size()\n",
        "\n",
        "      x = F.relu(self.ConvEn31(x))\n",
        "      x = F.relu(self.ConvEn32(x))\n",
        "      x = F.relu(self.ConvEn33(x))\n",
        "      x, ind3 = self.MaxEn(x)\n",
        "      size3 = x.size()\n",
        "\n",
        "      x = F.relu(self.ConvEn41(x))\n",
        "      x = F.relu(self.ConvEn42(x))\n",
        "      x = F.relu(self.ConvEn43(x))\n",
        "      x, ind4 = self.MaxEn(x)\n",
        "      size4 = x.size()\n",
        "\n",
        "      x = F.relu(self.ConvEn51(x))\n",
        "      x = F.relu(self.ConvEn52(x))\n",
        "      x = F.relu(self.ConvEn53(x))\n",
        "      x, ind5 = self.MaxEn(x)\n",
        "      size5 = x.size()\n",
        "\n",
        "      #Decoder\n",
        "      x = self.MaxDe(x, ind5, output_size=size4)\n",
        "      x = F.relu(self.ConvDe53(x))\n",
        "      x = F.relu(self.ConvDe52(x))\n",
        "      x = F.relu(self.ConvDe51(x))\n",
        "\n",
        "      x = self.MaxDe(x, ind4, output_size=size3)\n",
        "      x = F.relu(self.ConvDe43(x))\n",
        "      x = F.relu(self.ConvDe42(x))\n",
        "      x = F.relu(self.ConvDe41(x))\n",
        "\n",
        "      x = self.MaxDe(x, ind3, output_size=size2)\n",
        "      x = F.relu(self.ConvDe33(x))\n",
        "      x = F.relu(self.ConvDe32(x))\n",
        "      x = F.relu(self.ConvDe31(x))\n",
        "\n",
        "      x = self.MaxDe(x, ind2, output_size=size1)\n",
        "      x = F.relu(self.ConvDe22(x))\n",
        "      x = F.relu(self.ConvDe21(x))\n",
        "\n",
        "      x = self.MaxDe(x, ind1)\n",
        "      x = F.relu(self.ConvDe12(x))\n",
        "      x = self.ConvDe11(x)\n",
        "      return x\n"
      ],
      "metadata": {
        "id": "FDU4i72mCpgP"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e3f6fjvhKiA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.rand((1,1,232,196))\n",
        "print(image)\n",
        "model = SegNet()\n",
        "model(image)"
      ],
      "metadata": {
        "id": "lCLJDWJXttGA",
        "outputId": "f17da7e9-a7f6-4dcd-c79c-0f7c7ad6504e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.0583, 0.7006, 0.0518,  ..., 0.4546, 0.3720, 0.8920],\n",
            "          [0.3819, 0.8610, 0.2775,  ..., 0.0515, 0.3947, 0.6595],\n",
            "          [0.4078, 0.3445, 0.0616,  ..., 0.6648, 0.4819, 0.5768],\n",
            "          ...,\n",
            "          [0.2027, 0.6378, 0.6171,  ..., 0.5561, 0.0702, 0.9071],\n",
            "          [0.2896, 0.4228, 0.0903,  ..., 0.7746, 0.5915, 0.4330],\n",
            "          [0.1411, 0.4396, 0.0681,  ..., 0.7043, 0.6479, 0.4425]]]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
            "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.0511, -0.0540, -0.0558,  ..., -0.0561, -0.0553, -0.0514],\n",
              "          [-0.0523, -0.0545, -0.0560,  ..., -0.0562, -0.0552, -0.0483],\n",
              "          [-0.0505, -0.0525, -0.0558,  ..., -0.0565, -0.0554, -0.0490],\n",
              "          ...,\n",
              "          [-0.0507, -0.0555, -0.0577,  ..., -0.0547, -0.0563, -0.0485],\n",
              "          [-0.0508, -0.0549, -0.0536,  ..., -0.0557, -0.0564, -0.0498],\n",
              "          [-0.0433, -0.0470, -0.0468,  ..., -0.0457, -0.0457, -0.0436]]]],\n",
              "       grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criterion, optimizer, model => call train function\n",
        "dice = diceloss()\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "model = SegNet(batchnorm = True, initialization = True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "model.to(device)\n",
        "train(p_trdata = 0.5, transforms = True, model = model, criterion = bce, epochs = (0,40), crop=True, balanced=True, seed = 1234)\n"
      ],
      "metadata": {
        "id": "p1AElvEzuOvj",
        "outputId": "e04062fc-a98b-40a7-b1b0-0dab6b0b26c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "val\n",
            "initialization\n",
            "make folders\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
            "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ]
    }
  ]
}